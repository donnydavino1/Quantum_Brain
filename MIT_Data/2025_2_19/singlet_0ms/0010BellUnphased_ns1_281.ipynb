{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# from statistics import median\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import qutip as qt\n",
    "import nmrglue as ng\n",
    "\n",
    "\n",
    "# import pulsee.simulation as sim\n",
    "from plot_dm import plot_complex_density_matrix\n",
    "\n",
    "import tomography_helper_functions\n",
    "import tomography_helper_functions as helper\n",
    "# from tomography.tomography_helper_functions import projection_fortunato, plot_spectra_together\n",
    "# from tomography.tomography_helper_functions import index_to_element, integrate_simpson, integrate_optimized\n",
    "\n",
    "# import * is bad practice, but this is the easiest way to do quick theoretical calculations with this many variables.\n",
    "import operators as op\n",
    "import global_constants as glob\n",
    "from coeff_groups_class import CoefficientGroups\n",
    "\n",
    "from temporal_average import temporal_average\n",
    "\n",
    "# commented out cuz it causes my computer to not plot anything:\n",
    "#%matplotlib notebook\n",
    "\n",
    "plt.rcParams['figure.dpi'] = glob.DPI_DISPLAY"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# from statistics import median\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import qutip as qt\n",
    "import nmrglue as ng\n",
    "\n",
    "\n",
    "# import pulsee.simulation as sim\n",
    "from plot_dm import plot_complex_density_matrix\n",
    "\n",
    "import tomography_helper_functions\n",
    "import tomography_helper_functions as helper\n",
    "# from tomography.tomography_helper_functions import projection_fortunato, plot_spectra_together\n",
    "# from tomography.tomography_helper_functions import index_to_element, integrate_simpson, integrate_optimized\n",
    "\n",
    "# import * is bad practice, but this is the easiest way to do quick theoretical calculations with this many variables.\n",
    "import operators as op\n",
    "import global_constants as glob\n",
    "from coeff_groups_class import CoefficientGroups\n",
    "\n",
    "from temporal_average import temporal_average\n",
    "\n",
    "# commented out cuz it causes my computer to not plot anything:\n",
    "#%matplotlib notebook\n",
    "\n",
    "plt.rcParams['figure.dpi'] = glob.DPI_DISPLAY"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# DIFFERENT FOR THIS MEASUREMENT!\n",
    "SPECTRUM_WIDTH = 2000  # Hz\n",
    "\n",
    "\n",
    "# assert np.array_equal(freqs, freqs_local)\n",
    "\n",
    "#B_0 = 14.0921  # Tesla\n",
    "J = 22.0005  # Hz\n",
    "L_FREQ = -J/2\n",
    "R_FREQ = J/2\n",
    "PHASE_0=-145.696\n",
    "#15=0.8758057403799121\n",
    "#35=0.8678271596689194\n",
    "#-10=0.893466169581499\n",
    "# probably won't need...?\n",
    "#SPECTRUM_OFFSET = 49697.66\n",
    "#w_1_Bruker = 202474441.0  # Hz\n",
    "#w_2_Bruker = 202475194.8  # Hz\n",
    "#TEMP = 310  # Kelvin"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Importing Data\n",
    "Rearranged folders (from Donny's usual format) so that both P1 and P2 files are in the same folder. This way I don't have to deal with separate \"P1\" and \"P2\" folders."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "state_name = \"singlet_0ms\"\n",
    "rho_theory =  op.Rx_S(np.pi)*op.CNOT_Phased*op.H_1*op.CLEAN_0010*op.H_1.dag()*op.CNOT_Phased.dag()*op.Rx_S(np.pi).dag()\n",
    "plot_complex_density_matrix(rho_theory)\n",
    "display(rho_theory)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Bruker_folders_path = r\"C:\\Users\\lemon\\OneDrive - Brown University\\CNOT project\\tomography\\data\\Br-uker_folders\\2024_12_13\"\n",
    "data_folder = r\"C:\\Users\\donny\\Desktop\\desktop_files\\Brown\\All_data\\2_19_2025\\SAMPLE_143_19_Feb_25\\singlet_0ms_356_plus1\""
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Flip the frequency axis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating the frequency axis for the spectrum\n",
    "All data in below cell is from Donny's email & Bruker plots\n",
    "\n",
    "According to Bruker's software, the middle of the spectrum should be the experimental larmor frequency (with chemical shift included), and we can set this to 0 Hz. In other words, the frequency axis range is: (-spectrum_width/2, spectrum/2), with 0 in the middle, and left peak should occur at -$J$ and right peak at $J$"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "freqs, all_spectra_complex = temporal_average(data_folder, display_avg=True, DISPLAY_I=1)",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "freqs",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "freqs_local = np.linspace(-SPECTRUM_WIDTH / 2, SPECTRUM_WIDTH / 2, all_spectra_complex.shape[1])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "all_spectra = np.zeros((all_spectra_complex.shape[0] * 2, all_spectra_complex.shape[1]))\n",
    "\n",
    "for i in range(all_spectra_complex.shape[0]):\n",
    "    all_spectra[i * 2, :] = all_spectra_complex[i, :].real\n",
    "    all_spectra[i * 2 + 1, :] = all_spectra_complex[i, :].imag\n",
    "\n",
    "all_spectra.shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Everything Together"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "INT_WIDTH = 10  # in Hz. The width to integrate over.\n",
    "X_LIMS_DISPLAY = [-30, 30]\n",
    "\n",
    "\n",
    "# Making an offset so the red lines visually line up with the peaks\n",
    "p1_offset =2\n",
    "p1_freqs = (L_FREQ + p1_offset, R_FREQ + p1_offset)\n",
    "\n",
    "fig_1, axs_1 = helper.plot_spectra_together(freqs, all_spectra[:all_spectra.shape[0]//2],\n",
    "                                     glob.SPECTRA_NAMES, X_LIMS_DISPLAY, p1_freqs[0], p1_freqs[1], int_width=INT_WIDTH, share_y=True)\n",
    "fig_1.suptitle('ADP (Temporal Averaged) P1 Spectra', size=16)\n",
    "fig_1.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Making an offset so the red lines visually line up with the peaks\n",
    "p2_offset = 1\n",
    "p2_freqs = (L_FREQ + p2_offset, R_FREQ + p2_offset)\n",
    "\n",
    "fig_2, axs_2 = helper.plot_spectra_together(freqs, all_spectra[all_spectra.shape[0] // 2:], glob.SPECTRA_NAMES, X_LIMS_DISPLAY, p2_freqs[0], p2_freqs[1], int_width=INT_WIDTH, share_y=True)\n",
    "fig_2.suptitle('ADP (Temporal Averaged) P2 Spectra', size=16)\n",
    "fig_2.tight_layout()\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing for Tomography Calculations:\n",
    "\n",
    "We use convention of using the \"I\" to denote the first spin ($I_1$) and \"S\" the second spin ($I_2$)\n",
    "\n",
    "$(I=I_1, S=I_2)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick Check that our pulse sequences covers all 15 basis operators (not necessary)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "op.check_basis_complete()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Three Methods for calculating coefficients\n",
    "\n",
    "1. Just the height of the spectrum at the expected peak locations\n",
    "2. Integration of peaks (simpson method & trapezoid method, but both seem to give almost identical answers)\n",
    "3. (no longer used) Fitting a theoretical Lorentzian model to our data using scipy.curve_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First approach: get height of one data point closest to theoretical peak locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct a \"`coefficient groups`\". \n",
    "\"coefficient groups\" is a list of \"group\"s, with each group being a list of:\n",
    "\n",
    "`[operator, (c1, spectrum type), (c2, spectrum type), (c3, spectrum type), ...]`\n",
    "\n",
    "where the first element of the group is a product operator,\n",
    "\n",
    "and the following elements are tuples of: (coefficients corresponding to that operator, the type of spectrum which the coefficient came from).\n",
    "\n",
    "In the case of ADP there are two spectrum types: P1 and P2\n",
    "\n",
    "(each spectrum produces two coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "coeff_groups_height = CoefficientGroups()\n",
    "\n",
    "for (i, spectrum) in enumerate(all_spectra):\n",
    "    # Height of the point closest to each peak's frequency location\n",
    "    L = spectrum[np.absolute(freqs - L_FREQ).argmin()]\n",
    "    R = spectrum[np.absolute(freqs - R_FREQ).argmin()]\n",
    "    coeff_groups_height.add_coefficient(op.product_operators[i][0], L + R, helper.index_to_element(i))\n",
    "    coeff_groups_height.add_coefficient(op.product_operators[i][1], L - R, helper.index_to_element(i))\n",
    "    # print(f\"Spectrum {thermal_col_names[i]} L+R is: {(L+R):.1e}, L-R is {(L-R):.1e}\")\n",
    "\n",
    "print(f'number of groups is: {len(coeff_groups_height.data)} (<- should be 15)')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average the coefficients for each operator, and reconstruct the density matrix"
   ]
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Approach: integrate the raw data\n",
    "1. Integrate sample points using (`scipy.integrate.trapezoid`)\n",
    "2. Integrate sample points using (`scipy.integrate.simpson`)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "rho_naive = helper.integrate_simpson(freqs, all_spectra, p1_freqs, p2_freqs, INT_WIDTH, positive_diag=False)\n",
    "\n",
    "plot_complex_density_matrix(rho_naive)\n",
    "print(f\"projection of naive integration: {helper.projection_fortunato(rho_naive, rho_theory)}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Integrating with various different parameters to find the integration with the largest projection value:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "result_filename = f\"result_{state_name}.pickle\"\n",
    "error_filename = f\"result_{state_name}_error.pickle\"\n",
    "# result_filename = f\"result_{state_name}.pickle\"\n",
    "# error_filename = f\"result_{state_name}_error.pickle\"\n",
    "\n",
    "try:\n",
    "    with open(result_filename, \"rb\") as result_file:\n",
    "        best_rho_simpson, best_projection, best_offsets, best_int_width = pickle.load(result_file)\n",
    "    print(\"Found previously saved result file!\")\n",
    "        \n",
    "except FileNotFoundError:\n",
    "    print(\"Couldn't find saved result. Integrating and saving the result...\")\n",
    "    best_rho_simpson, best_projection, best_offsets, best_int_width, rho_error = \\\n",
    "        helper.integrate_optimized(freqs, all_spectra, p1_freqs, p2_freqs, rho_theory, return_error=True)\n",
    "                                   # p1_range=[0], p2_range=[0], width_range=[4])\n",
    "    with open(result_filename, \"wb\") as result_file:\n",
    "        pickle.dump([best_rho_simpson, best_projection, best_offsets, best_int_width], result_file)\n",
    "    with open(error_filename, \"wb\") as error_file:\n",
    "        pickle.dump(rho_error, error_file)\n",
    "\n",
    "\n",
    "try:\n",
    "    with open(error_filename, \"rb\") as error_file:\n",
    "        rho_error = pickle.load(error_file)\n",
    "    print(\"Found previously saved error file\")\n",
    "    \n",
    "except FileNotFoundError: # in the case where result file exists but error file doesn't.\n",
    "    print(\"Couldn't find saved error file. Calculating and saving error\")\n",
    "    rho_error = helper.integrate_simpson(freqs, all_spectra, p1_freqs, p2_freqs, best_int_width,\n",
    "                                         best_offsets[0], best_offsets[1], return_error=True)\n",
    "    with open(error_filename, \"wb\") as error_file:\n",
    "        pickle.dump(rho_error, error_file)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "print(f\"Best parameters: {best_offsets}, {best_int_width}\")\n",
    "print(f\"Best projection: {best_projection}\")\n",
    "plot_complex_density_matrix(best_rho_simpson, label_size=12, label_qubit=True, save_to=\"\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-02-21T18:15:32.533568Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "display(best_rho_simpson)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-02-21T18:15:32.537662Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "np.min(best_rho_simpson.diag())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-02-21T18:15:32.537662Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "best_rho_simpson - op.IDENTITY * np.min(best_rho_simpson.diag())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-02-21T18:15:32.537662Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import importlib\n",
    "importlib.reload(tomography_helper_functions)\n",
    "helper = tomography_helper_functions\n",
    "\n",
    "print(f\"qutip: {qt.fidelity(rho_theory, best_rho_simpson)}\")\n",
    "# print(f\"standard: {helper.projection_jozsa(rho_theory, best_rho_simpson)}\")\n",
    "# print(f\"standard reversed: {helper.projection_jozsa(best_rho_simpson, rho_theory)}\")\n",
    "# print(qt.fidelity(best_rho_simpson, rho_theory))\n",
    "print(f\"Fortunato: {helper.projection_fortunato(rho_theory, best_rho_simpson)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-02-21T18:15:32.544495Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "(rho_theory.sqrtm() * best_rho_simpson * rho_theory.sqrtm()).sqrtm() ** 2",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-21T18:15:32.595161Z",
     "start_time": "2025-02-21T18:15:32.544495Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-02-21T18:15:32.548397Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
